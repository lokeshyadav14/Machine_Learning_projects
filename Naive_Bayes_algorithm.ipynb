{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes\n",
        "---\n",
        "Naive Bayes classifiers are a collection of classification algorithms based on Bayes’ Theorem. It is not a single algorithm but a family of algorithms where all of them share a common principle, i.e. every pair of features being classified is independent of each other.\n"
      ],
      "metadata": {
        "id": "kJfozrR-yzE4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*There are three types of Naive Bayes Model, which are given below:*\n",
        "\n",
        "**Gaussian:** The Gaussian model assumes that features follow a normal distribution. This means if predictors take continuous values instead of discrete, then the model assumes that these values are sampled from the Gaussian distribution.\n",
        "\n",
        "**Multinomial:** The Multinomial Naïve Bayes classifier is used when the data is multinomial distributed. It is primarily used for document classification problems, it means a particular document belongs to which category such as Sports, Politics, education, etc.\n",
        "The classifier uses the frequency of words for the predictors.\n",
        "\n",
        "**Bernoulli:** The Bernoulli classifier works similar to the Multinomial classifier, but the predictor variables are the independent Booleans variables. Such as if a particular word is present or not in a document. This model is also famous for document classification tasks."
      ],
      "metadata": {
        "id": "OWSYAp2KzvJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**About data set**\n",
        "---\n",
        "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage."
      ],
      "metadata": {
        "id": "6AfcE50u0whT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive Bayes Gaussian Classifier**"
      ],
      "metadata": {
        "id": "JFNrleSVDgWY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82eHUYm3vLlW"
      },
      "outputs": [],
      "source": [
        "# importing required libraries\n",
        "import csv\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_csv(filename):\n",
        "  lines = csv.reader(open(r'/content/drive/MyDrive/Colab Notebooks/'+filename))\n",
        "  dataset = list(lines)\n",
        "  # removing heading column from dataset\n",
        "  del dataset[0]\n",
        "  # converting all data into float originally the data is in form of string\n",
        "  for i in range( len(dataset)):\n",
        "    dataset[i] = [float(x) for x in dataset[i]]\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "a-EVHd5p0SIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(dataset, split_ratio):\n",
        "  train_size = int(len(dataset) * split_ratio)\n",
        "  train_set = []\n",
        "  copy = list(dataset)\n",
        "  while len(train_set) < train_size:\n",
        "    index = random.randrange(len(copy))\n",
        "    # appending to training set and removing from testing set\n",
        "    train_set.append(copy.pop(index))\n",
        "  # returns training set and testing set\n",
        "  return [train_set, copy]"
      ],
      "metadata": {
        "id": "0lHLxzZT1-EW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def separate_by_class(dataset):\n",
        "  separated = {}\n",
        "  for i in range(len(dataset)):\n",
        "    vector = dataset[i]\n",
        "    if (vector[-1] not in separated):\n",
        "      separated[vector[-1]] = []\n",
        "    separated[vector[-1]].append(vector)\n",
        "  return separated"
      ],
      "metadata": {
        "id": "CE56-vVg3FBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean(numbers):\n",
        "  return sum(numbers)/float(len(numbers))"
      ],
      "metadata": {
        "id": "1ZZoWZpR4AIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standard_deviation(numbers):\n",
        "  avg = mean(numbers)\n",
        "  variance = sum([pow(x-avg,2) for x in numbers]) / float(len(numbers)-1)\n",
        "  return math.sqrt(variance)"
      ],
      "metadata": {
        "id": "G5VDQ-pR4RmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize(dataset):\n",
        "  # zip() function is used to map two or more list together, we can use * to unzip that mapping\n",
        "  summaries =  [(mean(attribute), standard_deviation(attribute)) for attribute in zip(*dataset)]\n",
        "  del summaries[-1]\n",
        "  return summaries"
      ],
      "metadata": {
        "id": "VJMRpI2D4vXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_by_class(dataset):\n",
        "  separated = separate_by_class(dataset)\n",
        "  summaries = {}\n",
        "  for class_value, instances in separated.items():\n",
        "    summaries[class_value] = summarize(instances)\n",
        "  return summaries"
      ],
      "metadata": {
        "id": "E-qgus0d6ZYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_probability(x, mean, standard_deviation):\n",
        "  exponent = math.exp(-(math.pow(x-mean, 2) / (2*math.pow(standard_deviation, 2))))\n",
        "  return (1/(math.sqrt(2*math.pi)*standard_deviation))*exponent"
      ],
      "metadata": {
        "id": "-4IzGYm77Bmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_class_probabilities(summaries, input_vector):\n",
        "  probabilities = {}\n",
        "  # items() returns a view object that contain key value pair\n",
        "  for class_value, class_summaries in summaries.items():\n",
        "    probabilities[class_value] = 1\n",
        "    for i in range(len(class_summaries)):\n",
        "      mean, standard_deviation = class_summaries[i]\n",
        "      x = input_vector[i]\n",
        "      probabilities[class_value] *= calculate_probability(x, mean, standard_deviation)\n",
        "  return probabilities\n"
      ],
      "metadata": {
        "id": "1SQHgMz18OkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(summaries, input_vector):\n",
        "  probabilities = calculate_class_probabilities(summaries, input_vector)\n",
        "  best_label, best_prob = None, -1\n",
        "  for class_value, probability in probabilities.items():\n",
        "    if best_label is None or probability > best_prob:\n",
        "      best_prob = probability\n",
        "      best_label = class_value\n",
        "  return best_label\n",
        "   "
      ],
      "metadata": {
        "id": "UV4ZIE5O93I8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(summaries, test_set):\n",
        "  predictions = []\n",
        "  for i in range(len(test_set)):\n",
        "    result = predict(summaries, test_set[i])\n",
        "    predictions.append(result)\n",
        "  return predictions"
      ],
      "metadata": {
        "id": "Q7BbsYzM_Nss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(test_set, predictions):\n",
        "  correct = 0\n",
        "  for x in range(len(test_set)):\n",
        "    if test_set[x][-1] == predictions[x]:\n",
        "      correct += 1\n",
        "  return (correct/float(len(test_set)))*100.0"
      ],
      "metadata": {
        "id": "67R_Ri-k_reS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code Driver**"
      ],
      "metadata": {
        "id": "arKA3ZeLANgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'diabetes.csv'\n",
        "split_ratio = 0.67\n",
        "dataset = load_csv(filename)\n",
        "training_set, test_set = split_dataset(dataset, split_ratio)\n",
        "print('Split {0} rows into train = {1} and test = {2} rows'.format(len(dataset), len(training_set), len(test_set)))\n",
        "\n",
        "# prepare model\n",
        "summaries = summarize_by_class(training_set)\n",
        "\n",
        "# test model\n",
        "predictions = get_predictions(summaries, test_set)\n",
        "accuracy = get_accuracy(test_set, predictions)\n",
        "print('Accuracy: {0}'.format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODPUd2O8AF1Z",
        "outputId": "e64bbe8b-5b8d-433e-823d-8e9b9997f1a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split 768 rows into train = 514 and test = 254 rows\n",
            "Accuracy: 75.19685039370079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VLmo3WUYCJZs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}